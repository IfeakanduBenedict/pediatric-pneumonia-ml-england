{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP4AP6Fc0LXK4ohzIUdhr2K",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/IfeakanduBenedict/pediatric-pneumonia-ml-england/blob/main/Pediatric_Pneumonia_Analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tD8UtGqy_7xO"
      },
      "source": [
        "# **Project Topic: Predicting Pediatric Pneumonia Hospitalisation Rates in English Local Authorities**\n",
        "   \n",
        "## Research Questions\n",
        "\n",
        "**PRIMARY**: To what extent can machine learning models predict emergency pneumonia hospitalisation rates among children and young people under 19 across English Local Authorities using socioeconomic deprivation, demographic vulnerability, and healthcare utilisation indicators?\n",
        "\n",
        "**SECONDARY**: Which socioeconomic, demographic, and healthcare-related factors contribute most to geographic inequalities in pneumonia hospitalisation rates among children and young people under 19 across England?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-aJPiWICYV3I"
      },
      "source": [
        "# **Notebook Setup and Installation of Needed Library**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8E4Hj6cl_7xQ",
        "outputId": "424bf8b7-1bfd-4493-c1f5-822d69903169"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ All libraries imported successfully!\n",
            "✓ Random seed set to: 42\n"
          ]
        }
      ],
      "source": [
        "# Data manipulation\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Visualization\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Statistical analysis\n",
        "from scipy import stats\n",
        "from scipy.stats import pearsonr, spearmanr\n",
        "\n",
        "# Machine Learning - Preprocessing\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
        "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
        "\n",
        "# Import Variance Inflation Factor (VIF) to detect multicollinearity\n",
        "# between predictor variables during feature evaluation.\n",
        "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
        "\n",
        "# Import hyperparameter tuning tools for model optimization\n",
        "# GridSearchCV performs exhaustive parameter search,\n",
        "# while RandomizedSearchCV samples parameter combinations for faster exploration.\n",
        "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
        "\n",
        "# Machine Learning - Models\n",
        "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
        "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.svm import SVR\n",
        "\n",
        "# Import statistical tests for regression assumptions validation\n",
        "# shapiro, normaltest: Test normality of residuals\n",
        "# het_breuschpagan: Test homoscedasticity (constant variance)\n",
        "# durbin_watson: Test independence (no autocorrelation)\n",
        "from scipy.stats import shapiro, normaltest\n",
        "from statsmodels.stats.diagnostic import het_breuschpagan\n",
        "from statsmodels.stats.stattools import durbin_watson\n",
        "\n",
        "# Import statsmodels for adding constant (required by Breusch-Pagan test)\n",
        "import statsmodels.api as sm\n",
        "\n",
        "# Machine Learning - Metrics\n",
        "from sklearn.metrics import (mean_squared_error, mean_absolute_error,\n",
        "                             r2_score, mean_absolute_percentage_error)\n",
        "\n",
        "# Model Interpretation\n",
        "import shap\n",
        "from sklearn.inspection import permutation_importance\n",
        "\n",
        "# Model Persistence\n",
        "import joblib\n",
        "import json\n",
        "from datetime import datetime\n",
        "\n",
        "# For handling file paths\n",
        "import os\n",
        "\n",
        "# Settings\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "RANDOM_STATE = 42\n",
        "np.random.seed(RANDOM_STATE)\n",
        "\n",
        "# Configure plotting style\n",
        "plt.style.use('seaborn-v0_8-whitegrid')\n",
        "sns.set_palette(\"husl\")\n",
        "sns.set_context(\"notebook\", font_scale=1.1)\n",
        "\n",
        "# Display settings\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.precision', 2)\n",
        "\n",
        "print(\"✓ All libraries imported successfully!\")\n",
        "print(f\"✓ Random seed set to: {RANDOM_STATE}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Connecting Google Drive**"
      ],
      "metadata": {
        "id": "fU81vGPIAPqF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import and mount Google Drive.\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SkYcC-iiAWoC",
        "outputId": "22947969-c349-42c1-c288-d989ecdeb967"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Navigating to the dataset folder in Google Drive\n",
        "os.chdir('/content/drive/MyDrive/')"
      ],
      "metadata": {
        "id": "vrCiatGeA2Lm"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}